{"docstore/metadata": {"ec6a4f09-6124-4fad-99b3-a736edce9cac": {"doc_hash": "50c7170cb21f4d4960f9ed0c64fdb725957e4957572b0c376aabacddb12ef8e2"}, "ceffac55-983c-4839-a7a8-4fd1a4bf6434": {"doc_hash": "e11deb23fb2044dce506c1ab9e75836171c98e0735a0ea57c18d2e96e7b18d2d", "ref_doc_id": "ec6a4f09-6124-4fad-99b3-a736edce9cac"}, "817c94cf-1f4f-4658-9848-bacadce57cd7": {"doc_hash": "b3ca84c6976f41c6b4a5ffa63c92b819029466ba9425e12cc1a04ccad158eb37", "ref_doc_id": "ec6a4f09-6124-4fad-99b3-a736edce9cac"}}, "docstore/data": {"ceffac55-983c-4839-a7a8-4fd1a4bf6434": {"__data__": {"id_": "ceffac55-983c-4839-a7a8-4fd1a4bf6434", "embedding": null, "metadata": {"file_path": "e:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\extracted_output\\Vedant Rajpurohit Resume new.txt", "file_name": "Vedant Rajpurohit Resume new.txt", "file_type": "text/plain", "file_size": 6306, "creation_date": "2024-09-19", "last_modified_date": "2024-09-19"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ec6a4f09-6124-4fad-99b3-a736edce9cac", "node_type": "4", "metadata": {"file_path": "e:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\extracted_output\\Vedant Rajpurohit Resume new.txt", "file_name": "Vedant Rajpurohit Resume new.txt", "file_type": "text/plain", "file_size": 6306, "creation_date": "2024-09-19", "last_modified_date": "2024-09-19"}, "hash": "50c7170cb21f4d4960f9ed0c64fdb725957e4957572b0c376aabacddb12ef8e2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "817c94cf-1f4f-4658-9848-bacadce57cd7", "node_type": "1", "metadata": {}, "hash": "780e3b1dcd72b25cb80f4b90c1972dff367902950f0f285d1cd25b62359bddd8", "class_name": "RelatedNodeInfo"}}, "text": "AWS Cloud\r\nAn individual who possesses a Bachelor of Technology degree in Computer Science Specialized with Machine learning and AI. Completed a hand-full of internships and worked as an teaching profession in IT field. Seeking a career in data science and Generative AI in a challenging environment where I can utilize my technical skills towards the development and implementation of new ideas and contribute to the growth of the organization.\r\nJunior AI Engineer\r\nved antrajpuroh it39 07@gmail.c om\r\nvedantrajpurohit3907@gmail.com\r\nSurat, India\r\nGitHub\r\n9979508828\r\nLinkedin\r\nLinkedin\r\nAWS Sagemaker, Bedrock\r\nGitHub\r\nComputer Vision(OpenCV)\r\nVector Stores (Pinecone, ChromaDB)\r\nModel Development\r\nDataset Handling\r\nChatbot Development and Testing\r\nAI Model Training and Optimization\r\nAI Frameworks (Langchain, LLamaindex, Crew AI)\r\nWORK EXPERIENCE\r\nAI Intern\r\nDhiwse Pvt Ltd.\r\nDec 2023 - July 2024 \r\nSurat Gujarat\r\nCompleted a total of five projects, including three 48-hour hackathons.\r\nDuring the hackathons, contributed to two projects as part of a team of three: the Ticketing System and the Recruitment Platform.\r\nDeveloped GitHub and resume scoring systems with custom criteria and OpenAI models with features for email communication,\r\nround creation, and position management for Recruitment Platform.\r\nDec 2023 -  J uly 2024  \r\nSurat Gujarat\r\nCompleted a t ota l of five projects, inclu ding three 48-h our hackath ons.\r\nDuring the  hacka thon s, contributed t o t wo proj ect s as part  of a te am of three:  the Ticke ting Syst em a nd the Recr uit\r\nment Platform.\r\nDeveloped a chatbot using LlamaIndex, Pinecone, and OpenAI for document-based information retrieval. auto-drafting of responses based on previously answered queries using OpenAI and admin interfaces for ticket management and responses for Ticketing System with auto-generating tickets from Mail, Discord, and YouTube.\r\nDeveloped GitHub and resume scoring systems with custom criteria and OpenAI models with features for email communication, round creation, and position management for Recruitment Platform.\r\nDeveloped an independent project 'LLM Evaluation and Testing Platform'.\r\nCollaborated on a VS Code extension that auto-generates acceptance criteria and execution plans from various data sources (PDFs, Word files, images, web links, GitHub codebases). Implemented LangChain and LlamaIndex loaders with OpenAI models for efficient results.\r\nDeveloped tools for auto-annotation of images in LabelImg and web components, including scraping and annot\r\nating web elements.\r\nLearned the concepts of Machine learning and deep learning\r\nMentor Sessions for project guidence.\r\nSept 2022 - Nov 2022 \r\nRemote\r\nDeveloped the project 'Hand Sign Language Recognition for American Alphabets, Hindi Varnmala, and Numbers' with integrated voice modulation.\r\nLearned the concepts of Machine learning and deep learning\r\nMentor Sessions for project guidence.\r\nPrepared project presentations and reports\r\nDhamdod, Kosamba, Surat Gujarat\r\nDesign lessons that incorporate technologies for students.\r\nJan 2023 - May 2023 \r\n\r\nACHIEVEMENTS\r\nPublished Research Paper on \"Human Computer\r\ninteracation with detection of hand gesture to improve\r\nartistic creativity\".\r\nResearch P\r\naper Link\r\nResearch Paper Link\r\nGoogle Drive Link\r\nEDUCATION\r\nBachelors in Computer Science Specialized with AI and ML\r\nP.P. Savani University\r\nOct 2020 - Apr 2024 \r\nCGPA: - 9.25\r\nHigher Secondary School (CBSE)\r\nJan 2018 -  Apr 2020 \r\nJan 2018 -  Apr 2020 \r\nPercentage: - 70\r\nPERSONAL PROJECTS\r\nLLM Evaluation and Testing Platform\r\nGitHub: - https://rb.gy/ztxxlkDeveloped a tool for concurrent evaluation of multiple language models with a single prompt and streaming outputs.\r\nBuilt evaluation features enabling users to assess prompt responses using custom evaluation metrics and GPT-4-based evaluation, leveraging OpenAI's GPT-4 model for high-quality feedback.\r\nEnabled individual parameter settings for each model and detailed metrics tracking (tokens used, response time, etc.).\r\nImplemented a prompt versioning system for saving and managing different versions of prompts.\r\nUsed Supabase for user authentication and data storage.\r\nUsed Supabase for user authentication and data storage.\r\nGitHub: - https://rb.gy/m6mgpt\r\nDeveloped a virtual painting application using OpenCV and Python, leveraging camera-based hand tracking.Created a custom hand tracking module with MediaPipe and CVZone libraries.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4443, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "817c94cf-1f4f-4658-9848-bacadce57cd7": {"__data__": {"id_": "817c94cf-1f4f-4658-9848-bacadce57cd7", "embedding": null, "metadata": {"file_path": "e:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\extracted_output\\Vedant Rajpurohit Resume new.txt", "file_name": "Vedant Rajpurohit Resume new.txt", "file_type": "text/plain", "file_size": 6306, "creation_date": "2024-09-19", "last_modified_date": "2024-09-19"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ec6a4f09-6124-4fad-99b3-a736edce9cac", "node_type": "4", "metadata": {"file_path": "e:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\extracted_output\\Vedant Rajpurohit Resume new.txt", "file_name": "Vedant Rajpurohit Resume new.txt", "file_type": "text/plain", "file_size": 6306, "creation_date": "2024-09-19", "last_modified_date": "2024-09-19"}, "hash": "50c7170cb21f4d4960f9ed0c64fdb725957e4957572b0c376aabacddb12ef8e2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ceffac55-983c-4839-a7a8-4fd1a4bf6434", "node_type": "1", "metadata": {"file_path": "e:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\extracted_output\\Vedant Rajpurohit Resume new.txt", "file_name": "Vedant Rajpurohit Resume new.txt", "file_type": "text/plain", "file_size": 6306, "creation_date": "2024-09-19", "last_modified_date": "2024-09-19"}, "hash": "e11deb23fb2044dce506c1ab9e75836171c98e0735a0ea57c18d2e96e7b18d2d", "class_name": "RelatedNodeInfo"}}, "text": "Built evaluation features enabling users to assess prompt responses using custom evaluation metrics and GPT-4-based evaluation, leveraging OpenAI's GPT-4 model for high-quality feedback.\r\nEnabled individual parameter settings for each model and detailed metrics tracking (tokens used, response time, etc.).\r\nImplemented a prompt versioning system for saving and managing different versions of prompts.\r\nUsed Supabase for user authentication and data storage.\r\nUsed Supabase for user authentication and data storage.\r\nGitHub: - https://rb.gy/m6mgpt\r\nDeveloped a virtual painting application using OpenCV and Python, leveraging camera-based hand tracking.Created a custom hand tracking module with MediaPipe and CVZone libraries.\r\nImplemented an intuitive interface with selectable colors and shapes via hand tracking.\r\nEnabled freehand drawing and shape drawing with adjustable size options.\r\nImplemented an intuitive interface with selectable colors and shapes via hand tracking.\r\nGitHub: -  https://rb.gy/dtfl2d\r\nCreated a custom dataset which is available on Kaggle and built custom models using MobileNet with additional layers.\r\nDesigned an interactive dashboard for language selection and hand sign tracking with real-time feedback.Implemented voiceover for recognized signs to assist deaf individuals in hearing the hand signs.\r\nDataset Available on kaggle: - https://rb.gy/c6vf9c\r\nDesigned an interactive dashboard for language selection and hand sign tracking with real-time feedback.\r\nGitHub: - https://rb.gy/88n32s\r\nUtilized custom libraries like NLTK for English and Hindi.Created a dataset for Gujarati available on Kaggle https://rb.gy/c6vf9c , sourced from internet and handwritten texts.\r\nImplemented a module that auto-detects the language of the input and provides POS tags.\r\nEnabled support for mixed-language sentences (combining English, Hindi, and Gujarati) with a configurable parameter.Designed a rule-based POS tagging system for Gujarati with rules developed with input from educators and experts.\r\nUtilized custom libraries like NLTK for English and Hindi.\r\nCreated a dataset for Gujarati available on Kaggle Full  Professional Proficiency \r\nImplemented a module that auto-detects the language of the input and provides POS tags.\r\nNative  or Bilingual Proficiency\r\nDesigned a rule-based POS tagging system for Gujarati with rules developed with input from educators and experts.\r\nNative  or Bilingual Proficiency\r\nEnglish\r\nElementary Proficiency\r\nHindi\r\nNative  or Bilingual Proficiency\r\nGujarati\r\nNative  or Bilingual Proficiency\r\nGerman\r\nElementary Proficiency", "mimetype": "text/plain", "start_char_idx": 3716, "end_char_idx": 6304, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"ec6a4f09-6124-4fad-99b3-a736edce9cac": {"node_ids": ["ceffac55-983c-4839-a7a8-4fd1a4bf6434", "817c94cf-1f4f-4658-9848-bacadce57cd7"], "metadata": {"file_path": "e:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\extracted_output\\Vedant Rajpurohit Resume new.txt", "file_name": "Vedant Rajpurohit Resume new.txt", "file_type": "text/plain", "file_size": 6306, "creation_date": "2024-09-19", "last_modified_date": "2024-09-19"}}}}