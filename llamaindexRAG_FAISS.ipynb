{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we are directly using VectorStoreIndex with faiss vector search but we can also use this with pinecone database go to the docs for studying.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# dimensions of llama3.1 with ollama\n",
    "d = 4096\n",
    "nlist = 10 # how many cells or how many voronoi cells\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "faiss_index = faiss.IndexIVFFlat(quantizer, d, nlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    Settings,\n",
    "    load_index_from_storage,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    ")\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.llms.groq import Groq\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./extracted_output\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='767316d7-b74a-40e0-8df0-784b74ce9064', embedding=None, metadata={'file_path': 'e:\\\\Codes\\\\Data Sciene\\\\AI\\\\FAISS_Vector_Seach\\\\extracted_output\\\\Vedant Rajpurohit Resume new.txt', 'file_name': 'Vedant Rajpurohit Resume new.txt', 'file_type': 'text/plain', 'file_size': 6306, 'creation_date': '2024-09-19', 'last_modified_date': '2024-09-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='AWS Cloud\\r\\nAn individual who possesses a Bachelor of Technology degree in Computer Science Specialized with Machine learning and AI. Completed a hand-full of internships and worked as an teaching profession in IT field. Seeking a career in data science and Generative AI in a challenging environment where I can utilize my technical skills towards the development and implementation of new ideas and contribute to the growth of the organization.\\r\\nJunior AI Engineer\\r\\nved antrajpuroh it39 07@gmail.c om\\r\\nvedantrajpurohit3907@gmail.com\\r\\nSurat, India\\r\\nGitHub\\r\\n9979508828\\r\\nLinkedin\\r\\nLinkedin\\r\\nAWS Sagemaker, Bedrock\\r\\nGitHub\\r\\nComputer Vision(OpenCV)\\r\\nVector Stores (Pinecone, ChromaDB)\\r\\nModel Development\\r\\nDataset Handling\\r\\nChatbot Development and Testing\\r\\nAI Model Training and Optimization\\r\\nAI Frameworks (Langchain, LLamaindex, Crew AI)\\r\\nWORK EXPERIENCE\\r\\nAI Intern\\r\\nDhiwse Pvt Ltd.\\r\\nDec 2023 - July 2024 \\r\\nSurat Gujarat\\r\\nCompleted a total of five projects, including three 48-hour hackathons.\\r\\nDuring the hackathons, contributed to two projects as part of a team of three: the Ticketing System and the Recruitment Platform.\\r\\nDeveloped GitHub and resume scoring systems with custom criteria and OpenAI models with features for email communication,\\r\\nround creation, and position management for Recruitment Platform.\\r\\nDec 2023 -  J uly 2024  \\r\\nSurat Gujarat\\r\\nCompleted a t ota l of five projects, inclu ding three 48-h our hackath ons.\\r\\nDuring the  hacka thon s, contributed t o t wo proj ect s as part  of a te am of three:  the Ticke ting Syst em a nd the Recr uit\\r\\nment Platform.\\r\\nDeveloped a chatbot using LlamaIndex, Pinecone, and OpenAI for document-based information retrieval. auto-drafting of responses based on previously answered queries using OpenAI and admin interfaces for ticket management and responses for Ticketing System with auto-generating tickets from Mail, Discord, and YouTube.\\r\\nDeveloped GitHub and resume scoring systems with custom criteria and OpenAI models with features for email communication, round creation, and position management for Recruitment Platform.\\r\\nDeveloped an independent project \\'LLM Evaluation and Testing Platform\\'.\\r\\nCollaborated on a VS Code extension that auto-generates acceptance criteria and execution plans from various data sources (PDFs, Word files, images, web links, GitHub codebases). Implemented LangChain and LlamaIndex loaders with OpenAI models for efficient results.\\r\\nDeveloped tools for auto-annotation of images in LabelImg and web components, including scraping and annot\\r\\nating web elements.\\r\\nLearned the concepts of Machine learning and deep learning\\r\\nMentor Sessions for project guidence.\\r\\nSept 2022 - Nov 2022 \\r\\nRemote\\r\\nDeveloped the project \\'Hand Sign Language Recognition for American Alphabets, Hindi Varnmala, and Numbers\\' with integrated voice modulation.\\r\\nLearned the concepts of Machine learning and deep learning\\r\\nMentor Sessions for project guidence.\\r\\nPrepared project presentations and reports\\r\\nDhamdod, Kosamba, Surat Gujarat\\r\\nDesign lessons that incorporate technologies for students.\\r\\nJan 2023 - May 2023 \\r\\n\\r\\nACHIEVEMENTS\\r\\nPublished Research Paper on \"Human Computer\\r\\ninteracation with detection of hand gesture to improve\\r\\nartistic creativity\".\\r\\nResearch P\\r\\naper Link\\r\\nResearch Paper Link\\r\\nGoogle Drive Link\\r\\nEDUCATION\\r\\nBachelors in Computer Science Specialized with AI and ML\\r\\nP.P. Savani University\\r\\nOct 2020 - Apr 2024 \\r\\nCGPA: - 9.25\\r\\nHigher Secondary School (CBSE)\\r\\nJan 2018 -  Apr 2020 \\r\\nJan 2018 -  Apr 2020 \\r\\nPercentage: - 70\\r\\nPERSONAL PROJECTS\\r\\nLLM Evaluation and Testing Platform\\r\\nGitHub: - https://rb.gy/ztxxlkDeveloped a tool for concurrent evaluation of multiple language models with a single prompt and streaming outputs.\\r\\nBuilt evaluation features enabling users to assess prompt responses using custom evaluation metrics and GPT-4-based evaluation, leveraging OpenAI\\'s GPT-4 model for high-quality feedback.\\r\\nEnabled individual parameter settings for each model and detailed metrics tracking (tokens used, response time, etc.).\\r\\nImplemented a prompt versioning system for saving and managing different versions of prompts.\\r\\nUsed Supabase for user authentication and data storage.\\r\\nUsed Supabase for user authentication and data storage.\\r\\nGitHub: - https://rb.gy/m6mgpt\\r\\nDeveloped a virtual painting application using OpenCV and Python, leveraging camera-based hand tracking.Created a custom hand tracking module with MediaPipe and CVZone libraries.\\r\\nImplemented an intuitive interface with selectable colors and shapes via hand tracking.\\r\\nEnabled freehand drawing and shape drawing with adjustable size options.\\r\\nImplemented an intuitive interface with selectable colors and shapes via hand tracking.\\r\\nGitHub: -  https://rb.gy/dtfl2d\\r\\nCreated a custom dataset which is available on Kaggle and built custom models using MobileNet with additional layers.\\r\\nDesigned an interactive dashboard for language selection and hand sign tracking with real-time feedback.Implemented voiceover for recognized signs to assist deaf individuals in hearing the hand signs.\\r\\nDataset Available on kaggle: - https://rb.gy/c6vf9c\\r\\nDesigned an interactive dashboard for language selection and hand sign tracking with real-time feedback.\\r\\nGitHub: - https://rb.gy/88n32s\\r\\nUtilized custom libraries like NLTK for English and Hindi.Created a dataset for Gujarati available on Kaggle https://rb.gy/c6vf9c , sourced from internet and handwritten texts.\\r\\nImplemented a module that auto-detects the language of the input and provides POS tags.\\r\\nEnabled support for mixed-language sentences (combining English, Hindi, and Gujarati) with a configurable parameter.Designed a rule-based POS tagging system for Gujarati with rules developed with input from educators and experts.\\r\\nUtilized custom libraries like NLTK for English and Hindi.\\r\\nCreated a dataset for Gujarati available on Kaggle Full  Professional Proficiency \\r\\nImplemented a module that auto-detects the language of the input and provides POS tags.\\r\\nNative  or Bilingual Proficiency\\r\\nDesigned a rule-based POS tagging system for Gujarati with rules developed with input from educators and experts.\\r\\nNative  or Bilingual Proficiency\\r\\nEnglish\\r\\nElementary Proficiency\\r\\nHindi\\r\\nNative  or Bilingual Proficiency\\r\\nGujarati\\r\\nNative  or Bilingual Proficiency\\r\\nGerman\\r\\nElementary Proficiency\\r\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = ollama_embedding = OllamaEmbedding(\n",
    "    model_name=\"llama3.1\",\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "Settings.llm = Groq(model=\"llama-3.1-70b-versatile\", api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error in virtual void __cdecl faiss::IndexIVFFlat::add_core(idx_t, const float *, const idx_t *, const idx_t *, void *) at D:\\a\\faiss-wheels\\faiss-wheels\\faiss\\faiss\\IndexIVFFlat.cpp:52: Error: 'is_trained' failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19304\\3503132332.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvector_store\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFaissVectorStore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaiss_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfaiss_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstorage_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStorageContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector_store\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvector_store\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m index = VectorStoreIndex.from_documents(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdocuments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32me:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\.venv\\lib\\site-packages\\llama_index\\core\\indices\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cls, documents, storage_context, show_progress, callback_manager, transformations, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[0mshow_progress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             )\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             return cls(\n\u001b[0m\u001b[0;32m    120\u001b[0m                 \u001b[0mnodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[0mstorage_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0mcallback_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\.venv\\lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;32melse\u001b[0m \u001b[0mSettings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         )\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insert_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minsert_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         super().__init__(\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[0mnodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mindex_struct\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_struct\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mstorage_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\.venv\\lib\\site-packages\\llama_index\\core\\indices\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"index_construction\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mindex_struct\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 index_struct = self.build_index_from_nodes(\n\u001b[0m\u001b[0;32m     78\u001b[0m                     \u001b[0mnodes\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mobjects\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                     \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                 )\n",
      "\u001b[1;32me:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\.venv\\lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m                 \u001b[1;34m\"Cannot build index from nodes with no content. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m                 \u001b[1;34m\"Please ensure all nodes have content.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             )\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_index_from_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minsert_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\.venv\\lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m                 )\n\u001b[0;32m    275\u001b[0m             ]\n\u001b[0;32m    276\u001b[0m             \u001b[0mrun_async_tasks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             self._add_nodes_to_index(\n\u001b[0m\u001b[0;32m    279\u001b[0m                 \u001b[0mindex_struct\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m                 \u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m                 \u001b[0mshow_progress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_progress\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\.venv\\lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnodes_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insert_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[0mnodes_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_node_with_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[0mnew_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vector_store\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minsert_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vector_store\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstores_text\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_store_nodes_override\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m                 \u001b[1;31m# NOTE: if the vector store doesn't store text,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\.venv\\lib\\site-packages\\llama_index\\vector_stores\\faiss\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, nodes, **add_kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mtext_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[0mtext_embedding_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mnew_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_faiss_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mntotal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_faiss_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_embedding_np\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m             \u001b[0mnew_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\.venv\\lib\\site-packages\\faiss\\class_wrappers.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_c\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\Codes\\Data Sciene\\AI\\FAISS_Vector_Seach\\.venv\\lib\\site-packages\\faiss\\swigfaiss_avx2.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, n, x)\u001b[0m\n\u001b[0;32m   5767\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5768\u001b[0m         \u001b[1;34mr\"\"\" Calls add_with_ids with NULL ids\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5769\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_swigfaiss_avx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndexIVF_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Error in virtual void __cdecl faiss::IndexIVFFlat::add_core(idx_t, const float *, const idx_t *, const idx_t *, void *) at D:\\a\\faiss-wheels\\faiss-wheels\\faiss\\faiss\\IndexIVFFlat.cpp:52: Error: 'is_trained' failed"
     ]
    }
   ],
   "source": [
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index to disk\n",
    "index.storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index from disk\n",
    "vector_store = FaissVectorStore.from_persist_dir(\"./storage\")\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store, persist_dir=\"./storage\"\n",
    ")\n",
    "index = load_index_from_storage(storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What research paper he has published\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The research paper published is on \"Human Computer interaction with detection of hand gesture to improve artistic creativity\"."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"{response}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
